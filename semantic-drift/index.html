<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic Drift | The Accidental Semiotics Shuffle</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { font-family: 'Georgia', serif; }
        .citation-card {
            transition: all 0.3s ease;
        }
        .citation-card.active {
            transform: scale(1.02);
            box-shadow: 0 10px 40px rgba(0,0,0,0.15);
        }
        .drift-meter {
            transition: width 0.5s ease;
        }
        .term-bubble {
            transition: all 0.3s ease;
        }
        .term-bubble:hover {
            transform: scale(1.1);
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.6; }
        }
        .pulse-warning {
            animation: pulse 2s infinite;
        }
        .connector-line {
            stroke-dasharray: 5;
            animation: dash 0.5s linear infinite;
        }
        @keyframes dash {
            to { stroke-dashoffset: -10; }
        }
    </style>
</head>
<body class="bg-gradient-to-br from-slate-50 to-blue-100 min-h-screen p-8">
    <div class="max-w-5xl mx-auto">
        <h1 class="text-4xl font-bold text-slate-800 mb-2">The Semantic Drift Tracker</h1>
        <p class="text-slate-600 mb-8 text-lg">Watch how technical AI terms lose precision as they travel through citations</p>

        <!-- Term Selector -->
        <div class="bg-white rounded-xl shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">Choose a Technical Term</h2>
            <div class="flex flex-wrap gap-3">
                <button onclick="selectTerm('understanding')" class="term-bubble px-4 py-2 rounded-full bg-blue-100 text-blue-700 hover:bg-blue-200 font-medium" data-term="understanding">Understanding</button>
                <button onclick="selectTerm('reasoning')" class="term-bubble px-4 py-2 rounded-full bg-purple-100 text-purple-700 hover:bg-purple-200 font-medium" data-term="reasoning">Reasoning</button>
                <button onclick="selectTerm('learning')" class="term-bubble px-4 py-2 rounded-full bg-green-100 text-green-700 hover:bg-green-200 font-medium" data-term="learning">Learning</button>
                <button onclick="selectTerm('memory')" class="term-bubble px-4 py-2 rounded-full bg-orange-100 text-orange-700 hover:bg-orange-200 font-medium" data-term="memory">Memory</button>
                <button onclick="selectTerm('attention')" class="term-bubble px-4 py-2 rounded-full bg-red-100 text-red-700 hover:bg-red-200 font-medium" data-term="attention">Attention</button>
                <button onclick="selectTerm('introspection')" class="term-bubble px-4 py-2 rounded-full bg-indigo-100 text-indigo-700 hover:bg-indigo-200 font-medium" data-term="introspection">Introspection</button>
            </div>
        </div>

        <!-- Drift Visualization -->
        <div class="bg-white rounded-xl shadow-lg p-6 mb-6">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-xl font-semibold text-gray-800">The Citation Chain: "<span id="current-term" class="text-blue-600">understanding</span>"</h2>
                <div class="text-sm">
                    <span class="text-gray-500">Semantic Drift:</span>
                    <span id="drift-percentage" class="font-bold text-red-500 ml-1">0%</span>
                </div>
            </div>

            <!-- Drift Meter -->
            <div class="mb-6">
                <div class="flex justify-between text-xs text-gray-500 mb-1">
                    <span>Technical (Precise)</span>
                    <span>Psychological (Vague)</span>
                </div>
                <div class="h-3 bg-gray-100 rounded-full overflow-hidden">
                    <div id="drift-bar" class="drift-meter h-full bg-gradient-to-r from-blue-400 via-yellow-400 to-red-500 rounded-full" style="width: 0%"></div>
                </div>
            </div>

            <!-- Citation Journey -->
            <div class="relative">
                <!-- Connection Lines SVG -->
                <svg class="absolute top-0 left-0 w-full h-full pointer-events-none" style="z-index: 0;">
                    <line x1="25%" y1="100" x2="50%" y2="100" class="connector-line stroke-gray-300 stroke-2" />
                    <line x1="50%" y1="100" x2="75%" y2="100" class="connector-line stroke-gray-300 stroke-2" />
                </svg>

                <!-- Citation Cards -->
                <div id="citation-chain" class="grid md:grid-cols-3 gap-6 relative z-10">
                    <!-- Cards will be generated by JS -->
                </div>
            </div>

            <!-- Step Slider -->
            <div class="mt-8">
                <input type="range" id="citation-step" min="0" max="2" value="0" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer accent-blue-500">
                <div class="flex justify-between text-sm text-gray-500 mt-2">
                    <span>Original Paper</span>
                    <span>Secondary Source</span>
                    <span>Popular Media</span>
                </div>
            </div>
        </div>

        <!-- What Changed Panel -->
        <div class="bg-white rounded-xl shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">What Got Lost in Translation</h2>

            <div class="grid md:grid-cols-2 gap-6">
                <!-- Dropped Qualifiers -->
                <div>
                    <h3 class="font-semibold text-red-600 mb-3 flex items-center gap-2">
                        <span>✂️</span> Dropped Qualifiers
                    </h3>
                    <ul id="dropped-qualifiers" class="space-y-2 text-sm">
                        <!-- Generated by JS -->
                    </ul>
                </div>

                <!-- Implied Claims -->
                <div>
                    <h3 class="font-semibold text-orange-600 mb-3 flex items-center gap-2">
                        <span>⚡</span> Implied Claims
                    </h3>
                    <ul id="implied-claims" class="space-y-2 text-sm">
                        <!-- Generated by JS -->
                    </ul>
                </div>
            </div>
        </div>

        <!-- The Pattern -->
        <div class="bg-white rounded-xl shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">The Semantic Drift Pattern</h2>

            <div class="space-y-6">
                <div class="flex items-start gap-4">
                    <div class="w-10 h-10 rounded-full bg-blue-100 flex items-center justify-center text-blue-600 font-bold flex-shrink-0">1</div>
                    <div>
                        <h3 class="font-semibold text-gray-800">Precise Technical Definition</h3>
                        <p class="text-gray-600 text-sm">Original paper defines the term carefully with metrics, benchmarks, and caveats. "We define 'understanding' as achieving >80% on reading comprehension benchmark X under conditions Y."</p>
                    </div>
                </div>

                <div class="flex items-start gap-4">
                    <div class="w-10 h-10 rounded-full bg-yellow-100 flex items-center justify-center text-yellow-600 font-bold flex-shrink-0">2</div>
                    <div>
                        <h3 class="font-semibold text-gray-800">Citation Simplification</h3>
                        <p class="text-gray-600 text-sm">Secondary sources cite the paper but drop qualifiers. "Recent research shows models can understand text." The benchmark and conditions vanish.</p>
                    </div>
                </div>

                <div class="flex items-start gap-4">
                    <div class="w-10 h-10 rounded-full bg-red-100 flex items-center justify-center text-red-600 font-bold flex-shrink-0">3</div>
                    <div>
                        <h3 class="font-semibold text-gray-800">Psychological Interpretation</h3>
                        <p class="text-gray-600 text-sm">Popular media and public discourse interpret the term psychologically. "AI now understands language like humans do." Technical achievement becomes philosophical claim.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Real Examples -->
        <div class="bg-white rounded-xl shadow-lg p-6 mb-6">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">Real-World Drift Examples</h2>

            <div class="grid md:grid-cols-2 gap-4">
                <div class="p-4 bg-slate-50 rounded-lg">
                    <h3 class="font-semibold text-slate-700 mb-2">"Attention" Mechanism</h3>
                    <p class="text-sm text-gray-600"><strong>Technical:</strong> Weighted sum of value vectors based on query-key similarity scores.</p>
                    <p class="text-sm text-gray-600 mt-1"><strong>Popular:</strong> "AI focuses on what's important, just like human attention."</p>
                </div>

                <div class="p-4 bg-slate-50 rounded-lg">
                    <h3 class="font-semibold text-slate-700 mb-2">"Learning" from Data</h3>
                    <p class="text-sm text-gray-600"><strong>Technical:</strong> Gradient descent optimization of loss function parameters.</p>
                    <p class="text-sm text-gray-600 mt-1"><strong>Popular:</strong> "AI learns and grows from experience like a child."</p>
                </div>

                <div class="p-4 bg-slate-50 rounded-lg">
                    <h3 class="font-semibold text-slate-700 mb-2">"Memory" in Transformers</h3>
                    <p class="text-sm text-gray-600"><strong>Technical:</strong> Key-value storage in attention layers; fixed context window.</p>
                    <p class="text-sm text-gray-600 mt-1"><strong>Popular:</strong> "AI remembers conversations and builds relationships."</p>
                </div>

                <div class="p-4 bg-slate-50 rounded-lg">
                    <h3 class="font-semibold text-slate-700 mb-2">"Reasoning" Capabilities</h3>
                    <p class="text-sm text-gray-600"><strong>Technical:</strong> Chain-of-thought prompting improves accuracy on benchmarks.</p>
                    <p class="text-sm text-gray-600 mt-1"><strong>Popular:</strong> "AI can think through problems logically."</p>
                </div>
            </div>
        </div>

        <!-- Key Insight -->
        <div class="bg-gradient-to-r from-blue-600 to-indigo-600 rounded-xl shadow-lg p-6 text-white">
            <h2 class="text-xl font-semibold mb-4">The Core Problem</h2>
            <p class="text-blue-100 leading-relaxed">
                The rigorous definition in the original paper provides "cover" for the sweeping claims made later by people who only read the abstract. Each citation is a game of telephone where technical precision gets replaced by intuitive (but misleading) psychological interpretation.
            </p>
            <p class="text-blue-100 leading-relaxed mt-4">
                The solution isn't to avoid metaphors—they're necessary for communication. It's to remember they <em>are</em> metaphors, and to check what the original paper actually measured before making claims about machine minds.
            </p>
        </div>

        <p class="text-center text-slate-500 mt-8 text-sm">
            Based on "The Accidental Semiotics Shuffle" from Adventure Capital
        </p>
    </div>

    <script>
        const terms = {
            understanding: {
                original: {
                    title: "Original ML Paper",
                    source: "NeurIPS 2023",
                    definition: "We operationalize 'understanding' as achieving >85% accuracy on the RACE++ benchmark with <2% variance across random seeds.",
                    qualifiers: [
                        "Limited to multiple-choice reading comprehension",
                        "English text only, average 300 words",
                        "No out-of-distribution generalization tested",
                        "Performance degrades to 62% on adversarial examples"
                    ]
                },
                secondary: {
                    title: "AI Research Blog",
                    source: "Tech publication",
                    definition: "New research demonstrates that large language models can understand text, achieving human-level performance on comprehension tasks.",
                    droppedQualifiers: [
                        "Multiple-choice format limitation",
                        "Specific benchmark conditions",
                        "Adversarial failure modes"
                    ],
                    impliedClaims: [
                        "Human-level suggests general understanding",
                        "'Can understand' implies active comprehension"
                    ]
                },
                popular: {
                    title: "News Headline",
                    source: "Major outlet",
                    definition: "AI Now Understands Language Like Humans: Researchers say machines have achieved genuine text comprehension.",
                    droppedQualifiers: [
                        "All benchmark limitations",
                        "Statistical nature of 'achievement'",
                        "Narrow task focus"
                    ],
                    impliedClaims: [
                        "Genuine comprehension (philosophical claim)",
                        "'Like humans' suggests similar cognitive process",
                        "General language understanding achieved"
                    ]
                }
            },
            reasoning: {
                original: {
                    title: "Original ML Paper",
                    source: "ICML 2024",
                    definition: "Chain-of-thought prompting improves accuracy on GSM8K math problems from 35% to 74% by decomposing problems into intermediate steps.",
                    qualifiers: [
                        "Specific to grade-school math word problems",
                        "Requires explicit step-by-step prompt format",
                        "Steps often contain calculation errors",
                        "Fails on problems requiring spatial reasoning"
                    ]
                },
                secondary: {
                    title: "AI Newsletter",
                    source: "Industry pub",
                    definition: "Breakthrough: AI systems can now reason through multi-step problems, showing dramatic improvements in mathematical performance.",
                    droppedQualifiers: [
                        "Grade-school level constraint",
                        "Prompt engineering requirement",
                        "Error rates in intermediate steps"
                    ],
                    impliedClaims: [
                        "'Reason through' suggests logical deduction",
                        "Mathematical performance implies broad math ability"
                    ]
                },
                popular: {
                    title: "Tech News",
                    source: "Viral article",
                    definition: "AI Can Think Now: New systems demonstrate human-like reasoning abilities, solving complex problems step-by-step.",
                    droppedQualifiers: [
                        "All task-specific limitations",
                        "Prompting requirements",
                        "Failure modes"
                    ],
                    impliedClaims: [
                        "'Think' implies conscious cognition",
                        "'Human-like reasoning' suggests similar process",
                        "'Complex problems' far exceeds actual capability"
                    ]
                }
            },
            learning: {
                original: {
                    title: "Original ML Paper",
                    source: "ICLR 2023",
                    definition: "We train the model using AdamW optimizer with lr=3e-4 on 1.5T tokens, minimizing cross-entropy loss over 100K steps.",
                    qualifiers: [
                        "Fixed dataset, no online learning",
                        "Optimization, not conceptual learning",
                        "Catastrophic forgetting on new tasks",
                        "No ability to selectively retain information"
                    ]
                },
                secondary: {
                    title: "Research Summary",
                    source: "Blog post",
                    definition: "The model learns patterns from massive datasets, developing sophisticated representations of language structure.",
                    droppedQualifiers: [
                        "Static training (no ongoing learning)",
                        "Optimization algorithm details",
                        "Forgetting limitations"
                    ],
                    impliedClaims: [
                        "'Learns patterns' suggests active learning",
                        "'Develops' implies growth over time"
                    ]
                },
                popular: {
                    title: "Magazine Feature",
                    source: "Popular science",
                    definition: "AI That Learns Like a Child: These systems absorb knowledge from everything they read, constantly growing smarter.",
                    droppedQualifiers: [
                        "All technical constraints",
                        "Static nature of trained models",
                        "No real-time learning"
                    ],
                    impliedClaims: [
                        "'Like a child' suggests developmental learning",
                        "'Constantly growing' implies ongoing improvement",
                        "'Absorbs knowledge' suggests understanding"
                    ]
                }
            },
            memory: {
                original: {
                    title: "Original Architecture Paper",
                    source: "Transformer paper",
                    definition: "The model maintains a context window of 4096 tokens using key-value attention mechanisms with O(n²) complexity.",
                    qualifiers: [
                        "Fixed window, older tokens lost",
                        "No persistent cross-session memory",
                        "Attention ≠ selective recall",
                        "Context treated uniformly, no 'importance' weighting"
                    ]
                },
                secondary: {
                    title: "Developer Docs",
                    source: "API documentation",
                    definition: "The model can remember context from earlier in the conversation, allowing for coherent multi-turn dialogue.",
                    droppedQualifiers: [
                        "Context window limits",
                        "No cross-session persistence",
                        "Mechanical nature of 'remembering'"
                    ],
                    impliedClaims: [
                        "'Remember' suggests active recall",
                        "Implies selective memory capabilities"
                    ]
                },
                popular: {
                    title: "User Review",
                    source: "Social media",
                    definition: "This AI actually remembers our past conversations! It's like talking to a friend who knows your history.",
                    droppedQualifiers: [
                        "All technical limitations",
                        "Session boundaries",
                        "No actual memory storage"
                    ],
                    impliedClaims: [
                        "'Like a friend' suggests relationship memory",
                        "'Knows your history' implies persistent identity model",
                        "Emotional/relational memory implied"
                    ]
                }
            },
            attention: {
                original: {
                    title: "Attention Is All You Need",
                    source: "NeurIPS 2017",
                    definition: "Attention computes compatibility between query and key vectors, producing weighted sums of value vectors: Attention(Q,K,V) = softmax(QK^T/√d)V",
                    qualifiers: [
                        "Purely mathematical operation",
                        "No concept of 'focus' or 'interest'",
                        "All positions processed simultaneously",
                        "Learned weights, not dynamic prioritization"
                    ]
                },
                secondary: {
                    title: "ML Tutorial",
                    source: "Educational content",
                    definition: "Attention allows the model to focus on relevant parts of the input when generating each output, similar to how humans attend to important information.",
                    droppedQualifiers: [
                        "Mathematical definition",
                        "Parallel processing nature",
                        "Fixed learned patterns"
                    ],
                    impliedClaims: [
                        "'Focus' implies selective cognition",
                        "'Similar to humans' suggests analogous process"
                    ]
                },
                popular: {
                    title: "Explainer Video",
                    source: "YouTube",
                    definition: "AI has learned to pay attention to what matters, ignoring irrelevant details just like our brains do when we concentrate.",
                    droppedQualifiers: [
                        "All mathematical grounding",
                        "Non-cognitive nature",
                        "Static learned behavior"
                    ],
                    impliedClaims: [
                        "'Pay attention' implies conscious choice",
                        "'Like our brains' suggests neural similarity",
                        "'Concentrate' implies effort and intention"
                    ]
                }
            },
            introspection: {
                original: {
                    title: "Self-Consistency Paper",
                    source: "Research paper",
                    definition: "We sample multiple reasoning paths and select the most consistent answer. This 'self-consistency' improves accuracy by 8% on average.",
                    qualifiers: [
                        "Multiple forward passes, not self-reflection",
                        "Consistency ≠ correctness",
                        "No access to internal states",
                        "Statistical aggregation, not meta-cognition"
                    ]
                },
                secondary: {
                    title: "Research Blog",
                    source: "Company blog",
                    definition: "Our model demonstrates introspection capabilities, checking its own reasoning and correcting errors before responding.",
                    droppedQualifiers: [
                        "Multiple-sample methodology",
                        "No actual self-access",
                        "Statistical nature of 'checking'"
                    ],
                    impliedClaims: [
                        "'Introspection' suggests self-awareness",
                        "'Checking its own reasoning' implies meta-cognition"
                    ]
                },
                popular: {
                    title: "News Article",
                    source: "Tech news",
                    definition: "AI Becomes Self-Aware: New systems can examine their own thoughts and know when they're wrong.",
                    droppedQualifiers: [
                        "All technical grounding",
                        "Probabilistic nature",
                        "No actual self-model"
                    ],
                    impliedClaims: [
                        "'Self-aware' is a massive philosophical leap",
                        "'Examine their own thoughts' implies consciousness",
                        "'Know when they're wrong' suggests epistemic awareness"
                    ]
                }
            }
        };

        let currentTerm = 'understanding';
        let currentStep = 0;

        function selectTerm(term) {
            currentTerm = term;
            currentStep = 0;
            document.getElementById('citation-step').value = 0;

            // Update button states
            document.querySelectorAll('.term-bubble').forEach(btn => {
                btn.classList.remove('ring-2', 'ring-offset-2');
                if (btn.dataset.term === term) {
                    btn.classList.add('ring-2', 'ring-offset-2');
                }
            });

            document.getElementById('current-term').textContent = term;
            updateVisualization();
        }

        function updateVisualization() {
            const data = terms[currentTerm];
            const stages = ['original', 'secondary', 'popular'];
            const colors = {
                original: { bg: 'bg-blue-50', border: 'border-blue-300', text: 'text-blue-800' },
                secondary: { bg: 'bg-yellow-50', border: 'border-yellow-300', text: 'text-yellow-800' },
                popular: { bg: 'bg-red-50', border: 'border-red-300', text: 'text-red-800' }
            };

            // Update citation cards
            const container = document.getElementById('citation-chain');
            container.innerHTML = '';

            stages.forEach((stage, i) => {
                const stageData = data[stage];
                const color = colors[stage];
                const isActive = i <= currentStep;
                const isCurrent = i === currentStep;

                const card = document.createElement('div');
                card.className = `citation-card p-4 rounded-lg border-2 ${color.bg} ${color.border} ${isActive ? 'opacity-100' : 'opacity-40'} ${isCurrent ? 'active' : ''}`;

                card.innerHTML = `
                    <div class="text-xs font-medium ${color.text} mb-1">${stageData.source}</div>
                    <h3 class="font-semibold text-gray-800 mb-2">${stageData.title}</h3>
                    <p class="text-sm text-gray-700">"${stageData.definition}"</p>
                    ${stage === 'original' ? `
                        <div class="mt-3 pt-3 border-t border-gray-200">
                            <div class="text-xs text-gray-500 font-medium mb-1">Qualifiers included:</div>
                            <ul class="text-xs text-gray-500 space-y-1">
                                ${stageData.qualifiers.map(q => `<li>• ${q}</li>`).join('')}
                            </ul>
                        </div>
                    ` : ''}
                `;

                container.appendChild(card);
            });

            // Update drift meter
            const driftPercent = currentStep * 50;
            document.getElementById('drift-bar').style.width = `${driftPercent}%`;
            document.getElementById('drift-percentage').textContent = `${driftPercent}%`;

            // Update dropped qualifiers
            const droppedList = document.getElementById('dropped-qualifiers');
            const impliedList = document.getElementById('implied-claims');

            if (currentStep === 0) {
                droppedList.innerHTML = '<li class="text-gray-400">Move the slider to see what gets lost...</li>';
                impliedList.innerHTML = '<li class="text-gray-400">Move the slider to see what gets added...</li>';
            } else {
                const currentStage = stages[currentStep];
                const stageData = data[currentStage];

                droppedList.innerHTML = stageData.droppedQualifiers
                    .map(q => `<li class="flex items-start gap-2"><span class="text-red-500">✗</span><span class="text-gray-600">${q}</span></li>`)
                    .join('');

                impliedList.innerHTML = stageData.impliedClaims
                    .map(c => `<li class="flex items-start gap-2"><span class="text-orange-500">!</span><span class="text-gray-600">${c}</span></li>`)
                    .join('');
            }
        }

        document.getElementById('citation-step').addEventListener('input', function() {
            currentStep = parseInt(this.value);
            updateVisualization();
        });

        // Initialize
        selectTerm('understanding');
    </script>
</body>
</html>
